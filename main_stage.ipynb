{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net.CSRNet import CSRNet\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from eval.eval_as_whole import eval_model\n",
    "from Dataset.EvalDatasetConstructor import EvalDatasetConstructor\n",
    "from Dataset.TrainDatasetConstructor import TrainDatasetConstructor\n",
    "from metrics import AEBatch, SEBatch\n",
    "from PIL import Image\n",
    "import time\n",
    "import torch\n",
    "# torch.backends.cudnn.benchmark=True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "config = {\n",
    "'min_mae':10240000,\n",
    "'min_loss':10240000,\n",
    "'eval_num':182,\n",
    "'train_num':300,\n",
    "'learning_rate': 1e-6,\n",
    "'train_batch_size': 1,\n",
    "'epoch': 20000,\n",
    "'eval_per_step': 300,\n",
    "'mode':'whole',\n",
    "'if_random_hsi':True,\n",
    "'if_flip':True,\n",
    "'stage':'numeration',\n",
    "'gt_map_path':\"/home/zzn/Documents/Datasets/part_A_final/train_data/gt_map_w_net\",\n",
    "'img_path':\"/home/zzn/Documents/Datasets/part_A_final/train_data/images\",\n",
    "'gt_map_path_t':\"/home/zzn/Documents/Datasets/part_A_final/test_data/gt_map_w_net\",\n",
    "'img_path_t':\"/home/zzn/Documents/Datasets/part_A_final/test_data/images\",\n",
    "'gt_path_t':\"/home/zzn/Documents/Datasets/part_A_final/test_data/ground_truth\",\n",
    "'model_save_path':\"/home/zzn/PycharmProjects/NAS_FPN/StateDicts/CSRNet_6-17_A.pkl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_load\n",
    "train_dataset = TrainDatasetConstructor(\n",
    "    config['img_path'],\n",
    "    config['gt_map_path'],\n",
    "    config['train_num'],\n",
    "    mode=config['mode'],\n",
    "    stage=config['stage'],\n",
    "    if_random_hsi=config['if_random_hsi'],\n",
    "    if_flip=config['if_flip'])\n",
    "eval_dataset = EvalDatasetConstructor(\n",
    "    config['img_path_t'],\n",
    "    config['gt_map_path_t'],\n",
    "    config['eval_num'],\n",
    "    mode=config['mode'],\n",
    "    stage=config['stage'])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=config['train_batch_size'])\n",
    "eval_loader = torch.utils.data.DataLoader(dataset=eval_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the gpu device\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")\n",
    "\n",
    "# model construct\n",
    "net = CSRNet().cuda()\n",
    "# net.load_state_dict(\n",
    "#     torch.load(\"/home/zzn/PycharmProjects/NAS_FPN/StateDicts/FPN_6-13_A.pkl\"))\n",
    "optimizer = torch.optim.Adam(net.parameters(), config['learning_rate'])\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     net.parameters(), 1e-7, momentum=0.95, weight_decay=5e-4)\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum').cuda()\n",
    "ae_batch = AEBatch().cuda()\n",
    "se_batch = SEBatch().cuda()\n",
    "modules = {\n",
    "    'model': net,\n",
    "    'shape': None,\n",
    "    'ae': ae_batch,\n",
    "    'se': se_batch,\n",
    "    'loss': criterion\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In step 0, epoch 0, loss = 59.6458178300124, eval_mae = 289.4889831542969, eval_rmse = 380.2806701660156, time cost eval = 35.83038020133972s\n",
      "In step 300, epoch 1, loss = 42.4774145765619, eval_mae = 161.80984497070312, eval_rmse = 230.26812744140625, time cost eval = 35.52651524543762s\n",
      "In step 600, epoch 2, loss = 38.784766742161345, eval_mae = 163.6050567626953, eval_rmse = 246.1707305908203, time cost eval = 35.40503787994385s\n",
      "In step 900, epoch 3, loss = 35.46890822347704, eval_mae = 125.86602783203125, eval_rmse = 194.7615966796875, time cost eval = 35.32987570762634s\n",
      "In step 1200, epoch 4, loss = 34.24294612433884, eval_mae = 145.8416290283203, eval_rmse = 210.3524932861328, time cost eval = 35.380532026290894s\n",
      "In step 1500, epoch 5, loss = 34.40345111784044, eval_mae = 141.38861083984375, eval_rmse = 217.57847595214844, time cost eval = 35.39902186393738s\n",
      "In step 1800, epoch 6, loss = 34.40743842753735, eval_mae = 169.80062866210938, eval_rmse = 249.60707092285156, time cost eval = 35.451313734054565s\n",
      "In step 2100, epoch 7, loss = 31.940110636281442, eval_mae = 111.37890625, eval_rmse = 173.79434204101562, time cost eval = 35.42500877380371s\n",
      "In step 2400, epoch 8, loss = 31.598838109236496, eval_mae = 121.92644500732422, eval_rmse = 176.60943603515625, time cost eval = 35.45377278327942s\n",
      "In step 2700, epoch 9, loss = 31.582816954497453, eval_mae = 174.6014404296875, eval_rmse = 224.97332763671875, time cost eval = 35.43037724494934s\n",
      "In step 3000, epoch 10, loss = 30.431352167339114, eval_mae = 116.42899322509766, eval_rmse = 166.31163024902344, time cost eval = 35.46171498298645s\n",
      "In step 3300, epoch 11, loss = 30.461483342306956, eval_mae = 122.12564086914062, eval_rmse = 179.48623657226562, time cost eval = 35.359487533569336s\n",
      "In step 3600, epoch 12, loss = 29.51437868652763, eval_mae = 93.82694244384766, eval_rmse = 145.81649780273438, time cost eval = 35.3797333240509s\n",
      "In step 3900, epoch 13, loss = 29.46089205637083, eval_mae = 106.65794372558594, eval_rmse = 152.37069702148438, time cost eval = 35.25756812095642s\n",
      "In step 4200, epoch 14, loss = 29.974338054656982, eval_mae = 142.2287139892578, eval_rmse = 193.06715393066406, time cost eval = 35.30189776420593s\n",
      "In step 4500, epoch 15, loss = 29.206284588509863, eval_mae = 101.63946533203125, eval_rmse = 151.03305053710938, time cost eval = 35.292213439941406s\n",
      "In step 4800, epoch 16, loss = 28.819810796569993, eval_mae = 98.88184356689453, eval_rmse = 145.0900115966797, time cost eval = 35.43209671974182s\n",
      "In step 5100, epoch 17, loss = 28.63999576621003, eval_mae = 88.1301498413086, eval_rmse = 134.75595092773438, time cost eval = 35.475072622299194s\n",
      "In step 5400, epoch 18, loss = 28.885631375260406, eval_mae = 127.24978637695312, eval_rmse = 165.36172485351562, time cost eval = 35.43957591056824s\n",
      "In step 5700, epoch 19, loss = 28.53444657482944, eval_mae = 98.5067367553711, eval_rmse = 143.20489501953125, time cost eval = 35.61548972129822s\n",
      "In step 6000, epoch 20, loss = 28.484325133837185, eval_mae = 115.35972595214844, eval_rmse = 160.8140411376953, time cost eval = 35.220462799072266s\n",
      "In step 6300, epoch 21, loss = 28.996799448034267, eval_mae = 170.3328857421875, eval_rmse = 208.64846801757812, time cost eval = 34.60405945777893s\n",
      "In step 6600, epoch 22, loss = 28.21053563107501, eval_mae = 90.60426330566406, eval_rmse = 134.67315673828125, time cost eval = 34.627477169036865s\n",
      "In step 6900, epoch 23, loss = 28.115431814403323, eval_mae = 82.6483383178711, eval_rmse = 130.23800659179688, time cost eval = 34.69106435775757s\n",
      "In step 7200, epoch 24, loss = 28.024875171891935, eval_mae = 102.16712951660156, eval_rmse = 142.77940368652344, time cost eval = 34.62834358215332s\n",
      "In step 7500, epoch 25, loss = 27.88426474948506, eval_mae = 84.84452819824219, eval_rmse = 131.0786590576172, time cost eval = 34.42549967765808s\n",
      "In step 7800, epoch 26, loss = 27.638786638176047, eval_mae = 87.04586791992188, eval_rmse = 126.71863555908203, time cost eval = 34.616504192352295s\n",
      "In step 8100, epoch 27, loss = 27.947428618158614, eval_mae = 89.20649719238281, eval_rmse = 132.7506866455078, time cost eval = 34.62822365760803s\n",
      "In step 8400, epoch 28, loss = 27.464384994664034, eval_mae = 87.86302185058594, eval_rmse = 129.73123168945312, time cost eval = 34.71241593360901s\n",
      "In step 8700, epoch 29, loss = 27.346094600446932, eval_mae = 82.32142639160156, eval_rmse = 124.23200225830078, time cost eval = 34.60203218460083s\n",
      "In step 9000, epoch 30, loss = 27.71115715425093, eval_mae = 109.12781524658203, eval_rmse = 147.74636840820312, time cost eval = 34.63984775543213s\n",
      "In step 9300, epoch 31, loss = 27.329428805099738, eval_mae = 106.57411193847656, eval_rmse = 138.88681030273438, time cost eval = 34.607757806777954s\n",
      "In step 9600, epoch 32, loss = 27.41037285196912, eval_mae = 113.35911560058594, eval_rmse = 148.54251098632812, time cost eval = 34.59408450126648s\n",
      "In step 9900, epoch 33, loss = 27.20344240455837, eval_mae = 87.9886703491211, eval_rmse = 125.17180633544922, time cost eval = 34.598928451538086s\n",
      "In step 10200, epoch 34, loss = 27.692138327347052, eval_mae = 130.82781982421875, eval_rmse = 167.98951721191406, time cost eval = 34.55341625213623s\n",
      "In step 10500, epoch 35, loss = 27.295048290556604, eval_mae = 111.39300537109375, eval_rmse = 144.84629821777344, time cost eval = 34.67223501205444s\n",
      "In step 10800, epoch 36, loss = 27.140440123421804, eval_mae = 100.33010864257812, eval_rmse = 135.61964416503906, time cost eval = 34.581992387771606s\n",
      "In step 11100, epoch 37, loss = 27.134171793749044, eval_mae = 101.2000961303711, eval_rmse = 140.91134643554688, time cost eval = 34.63314366340637s\n",
      "In step 11400, epoch 38, loss = 26.744328451680612, eval_mae = 75.51969146728516, eval_rmse = 116.47618865966797, time cost eval = 34.62103295326233s\n",
      "In step 11700, epoch 39, loss = 26.92551243698204, eval_mae = 80.54796600341797, eval_rmse = 124.08314514160156, time cost eval = 34.66512155532837s\n",
      "In step 12000, epoch 40, loss = 26.738629595263973, eval_mae = 75.87715148925781, eval_rmse = 116.4935302734375, time cost eval = 34.58833026885986s\n",
      "In step 12300, epoch 41, loss = 26.932004538211192, eval_mae = 81.72823333740234, eval_rmse = 122.37155151367188, time cost eval = 34.660340309143066s\n",
      "In step 12600, epoch 42, loss = 26.63126299931453, eval_mae = 74.86000061035156, eval_rmse = 115.87646484375, time cost eval = 34.63504338264465s\n",
      "In step 12900, epoch 43, loss = 26.578674795863392, eval_mae = 78.54067993164062, eval_rmse = 115.67875671386719, time cost eval = 34.6999454498291s\n",
      "In step 13200, epoch 44, loss = 26.5846412561752, eval_mae = 81.79888153076172, eval_rmse = 118.87972259521484, time cost eval = 34.6445107460022s\n",
      "In step 13500, epoch 45, loss = 27.378473661758086, eval_mae = 86.81898498535156, eval_rmse = 129.64370727539062, time cost eval = 34.69464445114136s\n",
      "In step 13800, epoch 46, loss = 26.639321590517902, eval_mae = 103.49525451660156, eval_rmse = 136.0846405029297, time cost eval = 34.597697257995605s\n",
      "In step 14100, epoch 47, loss = 26.36405661734906, eval_mae = 76.21148681640625, eval_rmse = 114.4044189453125, time cost eval = 34.64805364608765s\n",
      "In step 14400, epoch 48, loss = 26.771992644110878, eval_mae = 111.17850494384766, eval_rmse = 147.5867462158203, time cost eval = 34.70939326286316s\n",
      "In step 14700, epoch 49, loss = 26.321428891066667, eval_mae = 79.79713439941406, eval_rmse = 114.75584411621094, time cost eval = 34.66545033454895s\n",
      "In step 15000, epoch 50, loss = 26.573405770155098, eval_mae = 88.31704711914062, eval_rmse = 135.45925903320312, time cost eval = 34.677403926849365s\n",
      "In step 15300, epoch 51, loss = 26.16355360209287, eval_mae = 72.37655639648438, eval_rmse = 108.60790252685547, time cost eval = 34.59385395050049s\n",
      "In step 15600, epoch 52, loss = 27.01396629705534, eval_mae = 108.83387756347656, eval_rmse = 151.86465454101562, time cost eval = 34.62341117858887s\n",
      "In step 15900, epoch 53, loss = 25.977918789936947, eval_mae = 72.6557388305664, eval_rmse = 108.76542663574219, time cost eval = 34.68894362449646s\n",
      "In step 16200, epoch 54, loss = 25.957284677159656, eval_mae = 74.51666259765625, eval_rmse = 111.56807708740234, time cost eval = 34.61629772186279s\n",
      "In step 16500, epoch 55, loss = 26.009490931427084, eval_mae = 75.30123138427734, eval_rmse = 111.50382232666016, time cost eval = 34.60275316238403s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In step 16800, epoch 56, loss = 26.098655660073835, eval_mae = 77.04352569580078, eval_rmse = 112.6972427368164, time cost eval = 34.67562198638916s\n",
      "In step 17100, epoch 57, loss = 26.218149000471765, eval_mae = 91.3480224609375, eval_rmse = 125.14981079101562, time cost eval = 34.619566917419434s\n",
      "In step 17400, epoch 58, loss = 26.299895961206037, eval_mae = 75.89817810058594, eval_rmse = 111.7504653930664, time cost eval = 34.68700098991394s\n",
      "In step 17700, epoch 59, loss = 25.924794427641146, eval_mae = 72.67611694335938, eval_rmse = 110.78849029541016, time cost eval = 34.59959077835083s\n",
      "In step 18000, epoch 60, loss = 26.027276445221116, eval_mae = 75.37609100341797, eval_rmse = 112.4930191040039, time cost eval = 34.67645883560181s\n",
      "In step 18300, epoch 61, loss = 26.31022775697184, eval_mae = 89.9462661743164, eval_rmse = 121.63665771484375, time cost eval = 34.574082374572754s\n",
      "In step 18600, epoch 62, loss = 25.83505193610768, eval_mae = 75.10618591308594, eval_rmse = 111.77873992919922, time cost eval = 34.710381507873535s\n",
      "In step 18900, epoch 63, loss = 25.977337183533134, eval_mae = 77.89181518554688, eval_rmse = 114.02477264404297, time cost eval = 34.580230712890625s\n",
      "In step 19200, epoch 64, loss = 26.13297456437415, eval_mae = 88.46237182617188, eval_rmse = 121.16686248779297, time cost eval = 34.480650186538696s\n",
      "In step 19500, epoch 65, loss = 25.774977085354564, eval_mae = 71.59671783447266, eval_rmse = 110.1642837524414, time cost eval = 34.615439891815186s\n",
      "In step 19800, epoch 66, loss = 25.74138555290935, eval_mae = 81.0179214477539, eval_rmse = 114.00806427001953, time cost eval = 34.69154381752014s\n",
      "In step 20100, epoch 67, loss = 25.885055087424895, eval_mae = 73.51126098632812, eval_rmse = 113.57997131347656, time cost eval = 34.54579758644104s\n",
      "In step 20400, epoch 68, loss = 25.778492386524494, eval_mae = 72.73267364501953, eval_rmse = 111.93318939208984, time cost eval = 34.69226574897766s\n",
      "In step 20700, epoch 69, loss = 25.91829381277273, eval_mae = 76.30789184570312, eval_rmse = 120.5636978149414, time cost eval = 34.61081647872925s\n",
      "In step 21000, epoch 70, loss = 25.849660101827684, eval_mae = 83.88356018066406, eval_rmse = 116.82498168945312, time cost eval = 34.593876361846924s\n",
      "In step 21300, epoch 71, loss = 27.108944488095712, eval_mae = 88.372802734375, eval_rmse = 132.7643280029297, time cost eval = 34.62515330314636s\n",
      "In step 21600, epoch 72, loss = 26.006963124642006, eval_mae = 75.53728485107422, eval_rmse = 116.8226318359375, time cost eval = 34.65666222572327s\n",
      "In step 21900, epoch 73, loss = 25.480021176757393, eval_mae = 79.42069244384766, eval_rmse = 112.54803466796875, time cost eval = 34.622416496276855s\n",
      "In step 22200, epoch 74, loss = 25.663074201279944, eval_mae = 73.21259307861328, eval_rmse = 111.35047912597656, time cost eval = 34.69799208641052s\n",
      "In step 22500, epoch 75, loss = 25.489475474252806, eval_mae = 72.30364990234375, eval_rmse = 108.2599105834961, time cost eval = 34.65814256668091s\n",
      "In step 22800, epoch 76, loss = 25.636317554410997, eval_mae = 77.44409942626953, eval_rmse = 120.60942840576172, time cost eval = 34.68437170982361s\n",
      "In step 23100, epoch 77, loss = 25.782210686704616, eval_mae = 83.25022888183594, eval_rmse = 127.64911651611328, time cost eval = 34.74719214439392s\n",
      "In step 23400, epoch 78, loss = 25.51459138734, eval_mae = 72.49005126953125, eval_rmse = 113.30171203613281, time cost eval = 34.68393588066101s\n",
      "In step 23700, epoch 79, loss = 25.667817929288844, eval_mae = 89.53087615966797, eval_rmse = 123.73220825195312, time cost eval = 34.52126383781433s\n",
      "In step 24000, epoch 80, loss = 25.563240220258525, eval_mae = 84.91957092285156, eval_rmse = 116.93197631835938, time cost eval = 34.60546875s\n",
      "In step 24300, epoch 81, loss = 25.458312935881562, eval_mae = 84.8658676147461, eval_rmse = 116.5567855834961, time cost eval = 34.73641490936279s\n",
      "In step 24600, epoch 82, loss = 26.16490407042451, eval_mae = 120.1347427368164, eval_rmse = 156.91432189941406, time cost eval = 34.58340644836426s\n",
      "In step 24900, epoch 83, loss = 25.511619429011922, eval_mae = 72.3805923461914, eval_rmse = 111.33413696289062, time cost eval = 34.641775608062744s\n",
      "In step 25200, epoch 84, loss = 25.357966881531937, eval_mae = 70.96353149414062, eval_rmse = 108.2885971069336, time cost eval = 34.63126492500305s\n",
      "In step 25500, epoch 85, loss = 25.365375589538406, eval_mae = 71.20142364501953, eval_rmse = 108.42955780029297, time cost eval = 34.58997583389282s\n",
      "In step 25800, epoch 86, loss = 25.84103597651471, eval_mae = 79.8825454711914, eval_rmse = 117.97474670410156, time cost eval = 34.64256191253662s\n",
      "In step 26100, epoch 87, loss = 25.466329367606196, eval_mae = 82.82274627685547, eval_rmse = 115.4754409790039, time cost eval = 34.62089824676514s\n",
      "In step 26400, epoch 88, loss = 25.716133527703338, eval_mae = 100.68295288085938, eval_rmse = 137.00767517089844, time cost eval = 34.61970782279968s\n",
      "In step 26700, epoch 89, loss = 25.503365913590233, eval_mae = 77.833740234375, eval_rmse = 113.52742004394531, time cost eval = 34.60735106468201s\n",
      "In step 27000, epoch 90, loss = 25.413332226512196, eval_mae = 72.88953399658203, eval_rmse = 116.73643493652344, time cost eval = 34.68549466133118s\n",
      "In step 27300, epoch 91, loss = 25.357962183899932, eval_mae = 71.21180725097656, eval_rmse = 110.20043182373047, time cost eval = 34.66217494010925s\n",
      "In step 27600, epoch 92, loss = 25.41053470805451, eval_mae = 72.38514709472656, eval_rmse = 109.25764465332031, time cost eval = 34.72165536880493s\n",
      "In step 27900, epoch 93, loss = 25.36161056324676, eval_mae = 71.93953704833984, eval_rmse = 108.32444763183594, time cost eval = 34.59571933746338s\n",
      "In step 28200, epoch 94, loss = 25.37772940148364, eval_mae = 76.31646728515625, eval_rmse = 111.04255676269531, time cost eval = 34.640393018722534s\n",
      "In step 28500, epoch 95, loss = 25.60267802123185, eval_mae = 75.26022338867188, eval_rmse = 112.68607330322266, time cost eval = 34.615636587142944s\n",
      "In step 28800, epoch 96, loss = 26.219813116304167, eval_mae = 87.44841003417969, eval_rmse = 130.68402099609375, time cost eval = 34.64314150810242s\n",
      "In step 29100, epoch 97, loss = 26.121467877220322, eval_mae = 77.65271759033203, eval_rmse = 122.57038879394531, time cost eval = 34.650816202163696s\n",
      "In step 29400, epoch 98, loss = 25.191131278708742, eval_mae = 73.24394226074219, eval_rmse = 107.8805923461914, time cost eval = 34.7846155166626s\n",
      "In step 29700, epoch 99, loss = 25.48364513522976, eval_mae = 74.34909057617188, eval_rmse = 121.47175598144531, time cost eval = 34.55811405181885s\n",
      "In step 30000, epoch 100, loss = 25.44923439130678, eval_mae = 72.87715911865234, eval_rmse = 116.45240783691406, time cost eval = 34.632538080215454s\n",
      "In step 30300, epoch 101, loss = 25.466786662300866, eval_mae = 82.30818939208984, eval_rmse = 117.17503356933594, time cost eval = 34.60291075706482s\n",
      "In step 30600, epoch 102, loss = 25.77650455590133, eval_mae = 75.90070343017578, eval_rmse = 114.63031768798828, time cost eval = 34.708322525024414s\n",
      "In step 30900, epoch 103, loss = 25.291974251086895, eval_mae = 78.54267883300781, eval_rmse = 120.75975036621094, time cost eval = 34.31830453872681s\n",
      "In step 31200, epoch 104, loss = 25.15075926728301, eval_mae = 77.98399353027344, eval_rmse = 111.22760772705078, time cost eval = 34.57179379463196s\n",
      "In step 31500, epoch 105, loss = 25.153796699020887, eval_mae = 81.28144073486328, eval_rmse = 112.80594635009766, time cost eval = 34.63612174987793s\n",
      "In step 31800, epoch 106, loss = 25.120607872585673, eval_mae = 71.00678253173828, eval_rmse = 111.69691467285156, time cost eval = 34.61553955078125s\n",
      "In step 32100, epoch 107, loss = 25.34119672172672, eval_mae = 74.0205078125, eval_rmse = 118.34447479248047, time cost eval = 34.47226643562317s\n",
      "In step 32400, epoch 108, loss = 25.06229400765765, eval_mae = 76.44244384765625, eval_rmse = 117.4716796875, time cost eval = 34.654412508010864s\n",
      "In step 32700, epoch 109, loss = 25.022288636846856, eval_mae = 69.8255844116211, eval_rmse = 106.78138732910156, time cost eval = 34.721293449401855s\n",
      "In step 33000, epoch 110, loss = 25.037147683101697, eval_mae = 79.0965805053711, eval_rmse = 111.74845123291016, time cost eval = 34.76509952545166s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In step 33300, epoch 111, loss = 25.101916376051012, eval_mae = 69.4342041015625, eval_rmse = 108.7700424194336, time cost eval = 34.691051721572876s\n",
      "In step 33600, epoch 112, loss = 25.383316664905337, eval_mae = 72.18258666992188, eval_rmse = 116.65374755859375, time cost eval = 34.618518352508545s\n",
      "In step 33900, epoch 113, loss = 24.979572378672085, eval_mae = 72.54288482666016, eval_rmse = 112.81468963623047, time cost eval = 34.55200529098511s\n",
      "In step 34200, epoch 114, loss = 25.350491373093572, eval_mae = 87.07207489013672, eval_rmse = 119.74461364746094, time cost eval = 34.70164132118225s\n",
      "In step 34500, epoch 115, loss = 24.95082481614836, eval_mae = 78.4795913696289, eval_rmse = 109.8525390625, time cost eval = 34.64351558685303s\n",
      "In step 34800, epoch 116, loss = 24.938587351159736, eval_mae = 71.215087890625, eval_rmse = 107.13567352294922, time cost eval = 34.60934138298035s\n",
      "In step 35100, epoch 117, loss = 25.07770643915449, eval_mae = 70.85305786132812, eval_rmse = 111.05931854248047, time cost eval = 34.709941387176514s\n",
      "In step 35400, epoch 118, loss = 25.070970311269654, eval_mae = 75.68995666503906, eval_rmse = 110.35223388671875, time cost eval = 34.57179546356201s\n",
      "In step 35700, epoch 119, loss = 25.02062969155364, eval_mae = 75.18153381347656, eval_rmse = 109.5350112915039, time cost eval = 34.51477932929993s\n",
      "In step 36000, epoch 120, loss = 27.130014075027717, eval_mae = 145.9733123779297, eval_rmse = 192.36093139648438, time cost eval = 34.468878507614136s\n",
      "In step 36300, epoch 121, loss = 25.0553707251182, eval_mae = 70.40409088134766, eval_rmse = 114.09938049316406, time cost eval = 34.66929578781128s\n",
      "In step 36600, epoch 122, loss = 24.983939524535295, eval_mae = 70.25183868408203, eval_rmse = 104.15493774414062, time cost eval = 34.61693572998047s\n",
      "In step 36900, epoch 123, loss = 24.88896948164636, eval_mae = 68.08280181884766, eval_rmse = 105.7793960571289, time cost eval = 34.652703046798706s\n",
      "In step 37200, epoch 124, loss = 25.055083231611565, eval_mae = 70.99234008789062, eval_rmse = 104.94670867919922, time cost eval = 34.67304730415344s\n",
      "In step 37500, epoch 125, loss = 25.034506941889667, eval_mae = 72.002197265625, eval_rmse = 114.05599212646484, time cost eval = 34.75931930541992s\n",
      "In step 37800, epoch 126, loss = 24.969875819080478, eval_mae = 73.96043395996094, eval_rmse = 109.14969635009766, time cost eval = 34.66332387924194s\n",
      "In step 38100, epoch 127, loss = 24.779875317772667, eval_mae = 73.891845703125, eval_rmse = 106.751708984375, time cost eval = 34.66344952583313s\n",
      "In step 38400, epoch 128, loss = 24.913779038649338, eval_mae = 71.73218536376953, eval_rmse = 108.21849060058594, time cost eval = 34.73950958251953s\n",
      "In step 38700, epoch 129, loss = 25.217191483948255, eval_mae = 90.62017822265625, eval_rmse = 124.84295654296875, time cost eval = 34.66466927528381s\n",
      "In step 39000, epoch 130, loss = 24.98958050942683, eval_mae = 80.2300796508789, eval_rmse = 112.86201477050781, time cost eval = 34.67822504043579s\n",
      "In step 39300, epoch 131, loss = 24.866707231972242, eval_mae = 69.11421203613281, eval_rmse = 107.236328125, time cost eval = 34.556071043014526s\n",
      "In step 39600, epoch 132, loss = 25.462953175817216, eval_mae = 78.21002197265625, eval_rmse = 130.96875, time cost eval = 34.71470046043396s\n",
      "In step 39900, epoch 133, loss = 24.76161044246548, eval_mae = 69.50688934326172, eval_rmse = 105.88394927978516, time cost eval = 34.67990255355835s\n",
      "In step 40200, epoch 134, loss = 24.824484297207423, eval_mae = 69.49622344970703, eval_rmse = 107.58940887451172, time cost eval = 34.68245530128479s\n",
      "In step 40500, epoch 135, loss = 24.98335943903242, eval_mae = 81.03363037109375, eval_rmse = 113.4517593383789, time cost eval = 34.46401524543762s\n",
      "In step 40800, epoch 136, loss = 24.75854283636743, eval_mae = 71.67229461669922, eval_rmse = 105.97234344482422, time cost eval = 34.6165497303009s\n",
      "In step 41100, epoch 137, loss = 24.84995176372947, eval_mae = 75.61270904541016, eval_rmse = 108.93203735351562, time cost eval = 34.700735092163086s\n",
      "In step 41400, epoch 138, loss = 24.837810744296064, eval_mae = 68.44414520263672, eval_rmse = 104.11490631103516, time cost eval = 34.70123887062073s\n",
      "In step 41700, epoch 139, loss = 26.509600044606806, eval_mae = 122.46331787109375, eval_rmse = 169.93414306640625, time cost eval = 34.78494453430176s\n",
      "In step 42000, epoch 140, loss = 24.77860881470062, eval_mae = 69.26217651367188, eval_rmse = 105.55372619628906, time cost eval = 34.72841143608093s\n",
      "In step 42300, epoch 141, loss = 24.788472749374726, eval_mae = 67.79969787597656, eval_rmse = 108.7442626953125, time cost eval = 34.697691440582275s\n",
      "In step 42600, epoch 142, loss = 24.908900268785246, eval_mae = 70.50491333007812, eval_rmse = 111.25164794921875, time cost eval = 34.72988557815552s\n",
      "In step 42900, epoch 143, loss = 24.716559669473668, eval_mae = 69.34918212890625, eval_rmse = 106.8496322631836, time cost eval = 34.697298526763916s\n",
      "In step 43200, epoch 144, loss = 24.917779416828367, eval_mae = 71.81079864501953, eval_rmse = 108.82604217529297, time cost eval = 34.64915585517883s\n",
      "In step 43500, epoch 145, loss = 24.804595005381238, eval_mae = 74.92752838134766, eval_rmse = 108.2043228149414, time cost eval = 35.55864596366882s\n",
      "In step 43800, epoch 146, loss = 25.431273743346498, eval_mae = 71.82389831542969, eval_rmse = 122.77173614501953, time cost eval = 34.78479337692261s\n",
      "In step 44100, epoch 147, loss = 25.141380464637674, eval_mae = 107.66178894042969, eval_rmse = 138.3764190673828, time cost eval = 35.571635007858276s\n",
      "In step 44400, epoch 148, loss = 25.771727964118288, eval_mae = 125.7028579711914, eval_rmse = 163.88827514648438, time cost eval = 35.76573133468628s\n",
      "In step 44700, epoch 149, loss = 24.615958626453693, eval_mae = 71.8182601928711, eval_rmse = 103.85317993164062, time cost eval = 33.79306960105896s\n",
      "In step 45000, epoch 150, loss = 24.74640162043519, eval_mae = 68.38958740234375, eval_rmse = 107.45520782470703, time cost eval = 33.67241048812866s\n",
      "In step 45300, epoch 151, loss = 24.484088908185015, eval_mae = 67.818359375, eval_rmse = 102.64997863769531, time cost eval = 33.90576362609863s\n",
      "In step 45600, epoch 152, loss = 25.307388931840332, eval_mae = 73.53500366210938, eval_rmse = 124.35252380371094, time cost eval = 35.93842053413391s\n",
      "In step 45900, epoch 153, loss = 24.618277349314848, eval_mae = 67.46195983886719, eval_rmse = 102.58088684082031, time cost eval = 35.74218416213989s\n",
      "In step 46200, epoch 154, loss = 24.894918378892836, eval_mae = 77.60981750488281, eval_rmse = 109.1823959350586, time cost eval = 35.89410972595215s\n",
      "In step 46500, epoch 155, loss = 24.798437624187258, eval_mae = 73.17131805419922, eval_rmse = 106.91734313964844, time cost eval = 35.672646284103394s\n",
      "In step 46800, epoch 156, loss = 24.684264493512583, eval_mae = 67.8202133178711, eval_rmse = 106.12700653076172, time cost eval = 35.701855421066284s\n",
      "In step 47100, epoch 157, loss = 24.787438150290605, eval_mae = 80.6741714477539, eval_rmse = 111.44783782958984, time cost eval = 35.85736298561096s\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "eval_loss = []\n",
    "eval_mae = []\n",
    "eval_rmse = []\n",
    "for epoch_index in range(config['epoch']):\n",
    "    dataset = train_dataset.shuffle()\n",
    "    loss_list = []\n",
    "    time_per_epoch = 0\n",
    "    for train_img_index, train_img, train_gt in train_loader:\n",
    "        if step % config['eval_per_step'] == 0:\n",
    "            validate_MAE, validate_RMSE, validate_loss, time_cost = eval_model(\n",
    "                config, eval_loader, modules, False)\n",
    "            eval_loss.append(validate_loss)\n",
    "            eval_mae.append(validate_MAE)\n",
    "            eval_rmse.append(eval_rmse)\n",
    "            sys.stdout.write(\n",
    "                'In step {}, epoch {}, loss = {}, eval_mae = {}, eval_rmse = {}, time cost eval = {}s\\n'\n",
    "                .format(step, epoch_index, validate_loss, validate_MAE,\n",
    "                        validate_RMSE, time_cost))\n",
    "            sys.stdout.flush()\n",
    "            #             save model\n",
    "            if config['stage'] == 'numeration' and config[\n",
    "                    'min_mae'] > validate_MAE:\n",
    "                config['min_mae'] = validate_MAE\n",
    "                torch.save(net.state_dict(), config['model_save_path'])\n",
    "\n",
    "        net.train()\n",
    "        torch.cuda.empty_cache()\n",
    "        x = train_img\n",
    "        y = train_gt\n",
    "        start = time.time()\n",
    "        prediction = net(x)\n",
    "        loss = criterion(prediction, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_list.append(loss.data.item())\n",
    "        optimizer.step()\n",
    "\n",
    "        step += 1\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        time_per_epoch += end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scipy.io as scio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "perspective_dir = \"/home/zzn/Documents/Datasets/part_A_final/test_data/perspective_gt\"\n",
    "img_dir= \"/home/zzn/Documents/Datasets/part_A_final/test_data/images\"\n",
    "count = 0\n",
    "for i in range(182):\n",
    "    perspective_map_name = '/IMG_' + str(i + 1) + \".mat\"\n",
    "    perspective_map = scio.loadmat(perspective_dir + perspective_map_name)['pmap'][:]\n",
    "    if perspective_map[0][0] < 5:\n",
    "        count += 1\n",
    "        plt.imshow(Image.open(img_dir + '/IMG_' + str(i + 1) + \".jpg\"))\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
