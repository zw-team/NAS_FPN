{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "assert torch.cuda.is_available()\n",
    "%matplotlib inline\n",
    "cuda_device = torch.device(\"cuda:0\")\n",
    "torch.cuda.set_device(cuda_device)\n",
    "from config import config\n",
    "setting = config(\n",
    "    cuda_device, \n",
    "    model_save_name=\"/home/zzn/PycharmProjects/RESNET_FPN/StateDicts/DOMAIN_ADA_AplusB_7_13.pkl\", \n",
    "    dataset_name=\"SHA\",\n",
    "    lr=1e-4, \n",
    "    batch_size=5, \n",
    "    eval_per_step=120\n",
    ")\n",
    "setting_B = config(\n",
    "    cuda_device, \n",
    "    dataset_name=\"SHB\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_load\n",
    "from Dataset.DatasetConstructor import TrainDatasetConstructor,EvalDatasetConstructor\n",
    "train_dataset_A = TrainDatasetConstructor(setting.train_num, setting.train_img_path, setting.train_gt_map_path, \n",
    "                                          setting.train_pers_path, mode=setting.mode, dataset_name=setting.dataset_name, \n",
    "                                          device=setting.cuda_device, \n",
    "                                          if_random_hsi=setting.if_random_hsi, if_flip=setting.if_random_hsi)\n",
    "eval_dataset = EvalDatasetConstructor(setting.eval_num, setting.eval_img_path, setting.eval_gt_map_path, \n",
    "                                      setting.eval_pers_path, mode=setting.mode, dataset_name=setting.dataset_name, \n",
    "                                      device=setting.cuda_device)\n",
    "train_dataset_B = TrainDatasetConstructor(setting_B.train_num, setting_B.train_img_path, setting_B.train_gt_map_path, \n",
    "                                          setting_B.train_pers_path, mode=setting_B.mode, dataset_name=setting_B.dataset_name, \n",
    "                                          device=setting_B.cuda_device, \n",
    "                                          if_random_hsi=setting_B.if_random_hsi, if_flip=setting_B.if_random_hsi)\n",
    "train_loader_A = torch.utils.data.DataLoader(dataset=train_dataset_A, batch_size=setting.train_batch_size)\n",
    "train_loader_B = torch.utils.data.DataLoader(dataset=train_dataset_B, batch_size=setting.train_batch_size)\n",
    "eval_loader = torch.utils.data.DataLoader(dataset=eval_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model construct\n",
    "from net.RES_FPN.FPN import FPN\n",
    "from net.RES_FPN.Discriminator import Discriminator\n",
    "from eval.Estimator import Estimator\n",
    "net = FPN().to(setting.cuda_device)\n",
    "D = Discriminator().to(setting.cuda_device)\n",
    "G, decoder = net.getEncoder(), net.getDecoder()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), setting.learning_rate)\n",
    "optimizerD = torch.optim.Adam(D.parameters(), setting.learning_rate)\n",
    "optimizerG = torch.optim.Adam(G.parameters(), setting.learning_rate)\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum').to(setting.cuda_device)\n",
    "criterionGAN = torch.nn.BCELoss().to(setting.cuda_device)\n",
    "\n",
    "estimator = Estimator(setting, eval_loader, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "step = 0\n",
    "eval_loss, eval_mae, eval_rmse = [], [], []\n",
    "real_label = torch.ones(setting.train_batch_size, 1).to(setting.cuda_device)\n",
    "fake_label = torch.zeros(setting.train_batch_size, 1).to(setting.cuda_device)\n",
    "for epoch_index in range(setting.epoch):\n",
    "    train_dataset_A.shuffle()\n",
    "    train_dataset_B.shuffle()\n",
    "    loss_list = []\n",
    "    time_per_epoch = 0\n",
    "    for A_items, B_items in zip(train_loader_A, train_loader_B):\n",
    "        if step % setting.eval_per_step == 0:\n",
    "            validate_MAE, validate_RMSE, validate_loss, time_cost = estimator.evaluate(net, True)\n",
    "            eval_loss.append(validate_loss)\n",
    "            eval_mae.append(validate_MAE)\n",
    "            eval_rmse.append(eval_rmse)\n",
    "            sys.stdout.write(\n",
    "                'In step {}, epoch {}, loss = {}, eval_mae = {}, eval_rmse = {}, time cost eval = {}s\\n'\n",
    "                .format(step, epoch_index, validate_loss, validate_MAE,\n",
    "                        validate_RMSE, time_cost))\n",
    "            sys.stdout.flush()\n",
    "            #   save model\n",
    "            if setting.min_mae > validate_MAE:\n",
    "                setting.min_mae = validate_MAE\n",
    "                torch.save(net.state_dict(), setting.model_save_path)\n",
    "        \n",
    "        net.train()\n",
    "        torch.cuda.empty_cache()\n",
    "        (A_img_index, A_x, A_gt, A_pers), (B_img_index, B_x, B_gt, B_pers) = A_items, B_items\n",
    "        fake_h_1, _, _ , _= G(B_x)\n",
    "        fake_y = D(fake_h_1)\n",
    "        gan_G_loss = criterionGAN(fake_y, real_label)\n",
    "        optimizerG.zero_grad()\n",
    "        gan_G_loss.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            real_h_1, _, _ , _= G(A_x)\n",
    "            fake_h_1, _, _ , _= G(B_x)\n",
    "        real_y = D(real_h_1)\n",
    "        gan_real_loss = criterionGAN(real_y, real_label)\n",
    "        fake_y = D(fake_h_1)\n",
    "        gan_fake_loss = criterionGAN(fake_y, fake_label)\n",
    "        gan_D_loss = (gan_real_loss + gan_fake_loss) * 0.5\n",
    "        optimizerD.zero_grad()\n",
    "        gan_D_loss.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        real_out = net(A_x, A_pers)\n",
    "        l2_loss = criterion(real_out, A_gt)\n",
    "        optimizer.zero_grad()\n",
    "        l2_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        fake_out = net(B_x, B_pers)\n",
    "        l2_loss = criterion(fake_out, B_gt)\n",
    "        optimizer.zero_grad()\n",
    "        l2_loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
